{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2994,"status":"ok","timestamp":1643298396270,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"hqIQd4AjNfzh","outputId":"22d7995b-ba5c-44ae-8ca6-57baa881b50e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/Colab Notebooks\n","\n","os.chdir('./CycleSR/')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55450,"status":"ok","timestamp":1643298505944,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"i_yxcGKbrf4S","outputId":"83bd223a-86ca-49ea-8a3c-90ef00974736"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.3.1)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Found existing installation: scikit-image 0.19.1\n","Uninstalling scikit-image-0.19.1:\n","  Would remove:\n","    /usr/local/bin/skivi\n","    /usr/local/lib/python3.7/dist-packages/doc/ext/*\n","    /usr/local/lib/python3.7/dist-packages/scikit_image-0.19.1.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/scikit_image.libs/libgomp-f7e03b3e.so.1.0.0\n","    /usr/local/lib/python3.7/dist-packages/skimage/*\n","Proceed (Y/n)? n\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.19.1)\n","Requirement already satisfied: tifffile\u003e=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: imageio\u003e=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n","Requirement already satisfied: numpy\u003e=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.19.5)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,\u003e=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n","Requirement already satisfied: networkx\u003e=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (21.3)\n","Requirement already satisfied: PyWavelets\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging\u003e=20.0-\u003escikit-image) (3.0.7)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","0.19.1\n"]}],"source":["!pip install --upgrade pip\n","!pip uninstall scikit-image\n","!pip install scikit-image\n","import skimage\n","print(skimage.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34533,"status":"ok","timestamp":1643298540471,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"MPoRdq-gWrdb","outputId":"cae96f5e-1b7a-4aa2-cbdc-9d76d07fcfb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: lpips in /usr/local/lib/python3.7/dist-packages (0.1.4)\n","Requirement already satisfied: tqdm\u003e=4.28.1 in /usr/local/lib/python3.7/dist-packages (from lpips) (4.62.3)\n","Requirement already satisfied: numpy\u003e=1.14.3 in /usr/local/lib/python3.7/dist-packages (from lpips) (1.19.5)\n","Requirement already satisfied: scipy\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from lpips) (1.4.1)\n","Requirement already satisfied: torch\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from lpips) (1.10.0+cu111)\n","Requirement already satisfied: torchvision\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from lpips) (0.11.1+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch\u003e=0.4.0-\u003elpips) (3.10.0.2)\n","Requirement already satisfied: pillow!=8.3.0,\u003e=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision\u003e=0.2.1-\u003elpips) (7.1.2)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n","Requirement already satisfied: scipy\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n","Requirement already satisfied: numpy\u003e=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","/content/drive/MyDrive/Colab Notebooks/CycleSR/pytorch_wavelets\n","Processing /content/drive/MyDrive/Colab Notebooks/CycleSR/pytorch_wavelets\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch-\u003epytorch-wavelets==1.3.0) (3.10.0.2)\n","Building wheels for collected packages: pytorch-wavelets\n","  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.3.0-py3-none-any.whl size=55125 sha256=abf4adbbee08879794e70ff9ae4c1a1afabb844591aec2ddfa15399c4d2268e2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-19u7y1vh/wheels/c2/68/5e/51fa73a99f70fdfe25ce12e2bc3c4ece9a0b825a1a53184fe5\n","Successfully built pytorch-wavelets\n","Installing collected packages: pytorch-wavelets\n","  Attempting uninstall: pytorch-wavelets\n","    Found existing installation: pytorch-wavelets 1.3.0\n","    Uninstalling pytorch-wavelets-1.3.0:\n","      Successfully uninstalled pytorch-wavelets-1.3.0\n","Successfully installed pytorch-wavelets-1.3.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","/content/drive/MyDrive/Colab Notebooks/CycleSR\n"]}],"source":["# Prepare package\n","!pip install lpips\n","!pip install scikit-learn\n","if not os.path.exists(\"./pytorch_wavelets\"):\n","  !git clone https://github.com/fbcotter/pytorch_wavelets\n","%cd ./pytorch_wavelets/\n","!pip install .\n","%cd ../"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1028,"status":"ok","timestamp":1643300365265,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"qjL8Q3lIPE3z","outputId":"aca348da-630a-4d97-c306-01a72e9a24eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n","Loading model from: /usr/local/lib/python3.7/dist-packages/lpips/weights/v0.1/alex.pth\n"]}],"source":["import glob\n","import random\n","import os\n","from PIL import Image\n","import numpy as np\n","import time\n","import datetime\n","import sys\n","\n","import torch\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","\n","from tensorflow import summary\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import argparse\n","import itertools\n","import matplotlib.pyplot as plt\n","\n","from pytorch_wavelets import DWTForward\n","\n","import pdb\n","import skimage.metrics\n","\n","from tqdm import tqdm\n","\n","import lpips\n","loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n","# loss_fn_vgg = lpips.LPIPS(net='vgg') # closer to \"traditional\" perceptual loss, when used for optimization\n","\n","# import pytorch_fft.fft.autograd as fft\n","from utils import high_pass, low_pass"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1643300365265,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"JyD8gKBFVAnA","outputId":"12398aab-d65f-41c5-83cb-90738934253e"},"outputs":[{"name":"stdout","output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"]}],"source":["from torch.utils.tensorboard import SummaryWriter\n","\n","# default `log_dir` is \"runs\" - we'll be more specific here\n","writer = SummaryWriter('run/SR_baseline')\n","\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":485,"status":"ok","timestamp":1643300365748,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"FcgHTBToWfrz"},"outputs":[],"source":["# Helper Functions\n","def tensor2image(tensor):\n","    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n","    if image.shape[0] == 1:\n","        image = np.tile(image, (3,1,1))\n","    return image.astype(np.uint8)\n","\n","\n","class ReplayBuffer():\n","    def __init__(self, max_size=50):\n","        assert (max_size \u003e 0), 'Empty buffer or trying to create a black hole. Be careful.'\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def push_and_pop(self, data):\n","        to_return = []\n","        for element in data.data:\n","            element = torch.unsqueeze(element, 0)\n","            if len(self.data) \u003c self.max_size:\n","                self.data.append(element)\n","                to_return.append(element)\n","            else:\n","                if random.uniform(0,1) \u003e 0.5:\n","                    i = random.randint(0, self.max_size-1)\n","                    to_return.append(self.data[i].clone())\n","                    self.data[i] = element\n","                else:\n","                    to_return.append(element)\n","        return Variable(torch.cat(to_return))\n","\n","class LambdaLR():\n","    def __init__(self, n_epochs, offset, decay_start_epoch):\n","        assert ((n_epochs - decay_start_epoch) \u003e 0), \"Decay must start before the training session ends!\"\n","        self.n_epochs = n_epochs\n","        self.offset = offset\n","        self.decay_start_epoch = decay_start_epoch\n","\n","    def step(self, epoch):\n","        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n","\n","def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm2d') != -1:\n","        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant(m.bias.data, 0.0)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643300365748,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"LZPM5OT8PWXC"},"outputs":[],"source":["# Dataloader\n","class ImageDataset(Dataset):\n","    def __init__(self, root, transforms_A=None, transforms_B=None, unaligned=False, mode='train'):\n","        self.transformA = transforms.Compose(transforms_A)\n","        self.transformB = transforms.Compose(transforms_B)\n","\n","        self.unaligned = unaligned\n","\n","        self.files_A = sorted(glob.glob(os.path.join(root, 'trainA') + '/*.*'))\n","        self.files_B = sorted(glob.glob(os.path.join(root, 'trainB') + '/*.*'))\n","\n","    def __getitem__(self, index):\n","        img_A = Image.open(self.files_A[index % len(self.files_A)]).convert('L')\n","        item_A = self.transformA(img_A)\n","\n","        if self.unaligned:\n","            item_B = self.transformB(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]).convert('L'))\n","        else:\n","            item_B = self.transformB(Image.open(self.files_B[index % len(self.files_B)]).convert('L'))\n","\n","        return {'A': item_A, 'B': item_B}\n","\n","    def __len__(self):\n","        return max(len(self.files_A), len(self.files_B))"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643300365749,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"sEDL-1Gldu83"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    \"\"\"Defines a PatchGAN discriminator\"\"\"\n","\n","    def __init__(self, input_nc=1, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n","        \"\"\"Construct a PatchGAN discriminator\n","\n","        Parameters:\n","            input_nc (int)  -- the number of channels in input images\n","            ndf (int)       -- the number of filters in the last conv layer\n","            n_layers (int)  -- the number of conv layers in the discriminator\n","            norm_layer      -- normalization layer\n","        \"\"\"\n","        super(Discriminator, self).__init__()\n","        use_bias = True\n","        kw = 4\n","        padw = 1\n","        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n","        nf_mult = 1\n","        nf_mult_prev = 1\n","        for n in range(1, n_layers):  # gradually increase the number of filters\n","            nf_mult_prev = nf_mult\n","            nf_mult = min(2 ** n, 8)\n","            sequence += [\n","                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n","                norm_layer(ndf * nf_mult),\n","                nn.LeakyReLU(0.2, True)\n","            ]\n","\n","        nf_mult_prev = nf_mult\n","        nf_mult = min(2 ** n_layers, 8)\n","        sequence += [\n","            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n","            norm_layer(ndf * nf_mult),\n","            nn.LeakyReLU(0.2, True)\n","        ]\n","\n","        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n","        self.model = nn.Sequential(*sequence)\n","\n","    def forward(self, input):\n","        \"\"\"Standard forward.\"\"\"\n","        return self.model(input)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643300365749,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"UUf4-vPfUv64"},"outputs":[],"source":["def set_requires_grad(nets, requires_grad=False):\n","    \"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n","    Parameters:\n","        nets (network list)   -- a list of networks\n","        requires_grad (bool)  -- whether the networks require gradients or not\n","    \"\"\"\n","    if not isinstance(nets, list):\n","        nets = [nets]\n","    for net in nets:\n","        if net is not None:\n","            for param in net.parameters():\n","                param.requires_grad = requires_grad"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643300365749,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"6CIIbmIMnnyl"},"outputs":[],"source":["def save_sample(epoch, tensor, suffix=\"_real\"):\n","    output = tensor.cpu().detach().numpy().squeeze(0).squeeze(0)\n","    plt.imsave('./tmp/image_'+str(epoch+1)+suffix+'.jpeg', output, cmap=\"gray\")"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1643300365749,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"ZXf69PfiRuSj"},"outputs":[],"source":["#### Defination of local variables\n","input_nc = 1\n","output_nc = 1\n","batchSize = 1\n","size_A, size_B = 256, 256\n","lr = 2e-4\n","n_epochs, epoch, decay_epoch = 100, 0, 10\n","n_cpu = 2\n","dataroot = \"./dataset/OCTA_baseline\"\n","cuda = True"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643300365750,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"Kb1cpw_vP70j"},"outputs":[],"source":["if torch.cuda.is_available() and not cuda:\n","    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643300365750,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"pYt_XgC5ea_6"},"outputs":[],"source":["class UnetGenerator(nn.Module):\n","    \"\"\"Create a Unet-based generator\"\"\"\n","\n","    def __init__(self, input_nc=1, output_nc=1, num_downs=8, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n","        \"\"\"Construct a Unet generator\n","        Parameters:\n","            input_nc (int)  -- the number of channels in input images\n","            output_nc (int) -- the number of channels in output images\n","            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n","                                image of size 128x128 will become of size 1x1 # at the bottleneck\n","            ngf (int)       -- the number of filters in the last conv layer\n","            norm_layer      -- normalization layer\n","        We construct the U-Net from the innermost layer to the outermost layer.\n","        It is a recursive process.\n","        \"\"\"\n","        super(UnetGenerator, self).__init__()\n","        # construct unet structure\n","        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)  # add the innermost layer\n","        for i in range(num_downs - 5):          # add intermediate layers with ngf * 8 filters\n","            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n","        # gradually reduce the number of filters from ngf * 8 to ngf\n","        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n","        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n","        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n","        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)  # add the outermost layer\n","\n","    def forward(self, input):\n","        \"\"\"Standard forward\"\"\"\n","        hf = high_pass(input[0], i=5).unsqueeze(0).unsqueeze(0) # (1, 320) 5\n","        input = (hf+input)/2.0\n","        return self.model(input)\n","\n","\n","class UnetSkipConnectionBlock(nn.Module):\n","    \"\"\"Defines the Unet submodule with skip connection.\n","        X -------------------identity----------------------\n","        |-- downsampling -- |submodule| -- upsampling --|\n","    \"\"\"\n","\n","    def __init__(self, outer_nc, inner_nc, input_nc=None,\n","                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n","        \"\"\"Construct a Unet submodule with skip connections.\n","        Parameters:\n","            outer_nc (int) -- the number of filters in the outer conv layer\n","            inner_nc (int) -- the number of filters in the inner conv layer\n","            input_nc (int) -- the number of channels in input images/features\n","            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n","            outermost (bool)    -- if this module is the outermost module\n","            innermost (bool)    -- if this module is the innermost module\n","            norm_layer          -- normalization layer\n","            use_dropout (bool)  -- if use dropout layers.\n","        \"\"\"\n","        super(UnetSkipConnectionBlock, self).__init__()\n","        self.outermost = outermost\n","        use_bias = True\n","        if input_nc is None:\n","            input_nc = outer_nc\n","        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n","                             stride=2, padding=1, bias=use_bias)\n","        downrelu = nn.LeakyReLU(0.2, True)\n","        downnorm = norm_layer(inner_nc)\n","        uprelu = nn.ReLU(True)\n","        upnorm = norm_layer(outer_nc)\n","\n","        if outermost:\n","            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n","                                        kernel_size=4, stride=2,\n","                                        padding=1)\n","            down = [downconv]\n","            up = [uprelu, upconv, nn.Tanh()]\n","            model = down + [submodule] + up\n","        elif innermost:\n","            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n","                                        kernel_size=4, stride=2,\n","                                        padding=1, bias=use_bias)\n","            down = [downrelu, downconv]\n","            up = [uprelu, upconv, upnorm]\n","            model = down + up\n","        else:\n","            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n","                                        kernel_size=4, stride=2,\n","                                        padding=1, bias=use_bias)\n","            down = [downrelu, downconv, downnorm]\n","            up = [uprelu, upconv, upnorm]\n","\n","            if use_dropout:\n","                model = down + [submodule] + up + [nn.Dropout(0.5)]\n","            else:\n","                model = down + [submodule] + up\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        if self.outermost:\n","            return self.model(x)\n","        else:   # add skip connections\n","            return torch.cat([x, self.model(x)], 1)"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1643300365750,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"xg1PyC9FKoa4"},"outputs":[],"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1328,"status":"ok","timestamp":1643300367073,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"eMYhch_iPt4K","outputId":"1b513dc8-ef2c-4949-ca23-81a86dfe3c41"},"outputs":[{"name":"stdout","output_type":"stream","text":["354\n"]}],"source":["###### Definition of variables ######\n","# Networks\n","\n","netG_A2B = UnetGenerator()\n","netG_B2A = UnetGenerator()\n","netD_A = Discriminator()\n","netD_B = Discriminator()\n","\n","if cuda:\n","    netG_A2B.cuda()\n","    netG_B2A.cuda()\n","    netD_A.cuda()\n","    netD_B.cuda()\n","\n","netG_A2B.apply(weights_init_normal)\n","netG_B2A.apply(weights_init_normal)\n","netD_A.apply(weights_init_normal)\n","netD_B.apply(weights_init_normal)\n","\n","# Lossess\n","criterion_GAN = torch.nn.MSELoss()\n","criterion_cycle = torch.nn.L1Loss()\n","# criterion_phase = phase_consistency_loss()\n","criterion_identity = torch.nn.L1Loss()\n","\n","\n","# Optimizers \u0026 LR schedulers\n","optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=lr, betas=(0.5, 0.999))\n","optimizer_D = torch.optim.Adam(itertools.chain(netD_A.parameters(), netD_B.parameters()), lr=lr, betas=(0.5, 0.999))\n","\n","\n","lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n","lr_scheduler_D = torch.optim.lr_scheduler.LambdaLR(optimizer_D, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n","\n","# Inputs \u0026 targets memory allocation\n","Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n","input_A = Tensor(batchSize, input_nc, size_A, size_A)\n","# input_B = Tensor(batchSize, output_nc, size_A, size_A)\n","input_B = Tensor(batchSize, output_nc, size_B, size_B)\n","target_real = Variable(Tensor(batchSize).fill_(1.0), requires_grad=False)\n","target_fake = Variable(Tensor(batchSize).fill_(0.0), requires_grad=False)\n","\n","fake_A_buffer = ReplayBuffer()\n","fake_B_buffer = ReplayBuffer()\n","\n","# Dataset loader\n","transforms_A = [ \n","                transforms.ToTensor(),\n","                # transforms.Normalize((0.246), (0.170)),\n","                transforms.Normalize((0.5), (0.5)),\n","                # transforms.CenterCrop(size_A),\n","                transforms.RandomCrop((size_A, size_A))\n","                ]\n","                \n","transforms_B = [ \n","                transforms.ToTensor(),\n","                transforms.Normalize((0.5), (0.5)),\n","                # transforms.Normalize((0.286), (0.200)),\n","                # transforms.CenterCrop(size_B),\n","                transforms.RandomCrop((size_B, size_B))\n","                ]\n","dataset = ImageDataset(dataroot, transforms_A=transforms_A, transforms_B=transforms_B, unaligned=True)\n","print (len(dataset))\n","dataloader = DataLoader(dataset, batch_size=batchSize, shuffle=True)\n","\n","# Loss plot\n","# logger = Logger(n_epochs, len(dataloader))\n","###################################\n"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1643300367074,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"6aSlEi1IjSX0"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1643300367074,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"XyVs_ec6rLsf"},"outputs":[],"source":["# lr_img = Image.open(\"./test/6x6_256/270_3.png\").convert('L')\n","# hr_img = Image.open(\"./test/3x3_256/270_6.png\").convert('L')\n","\n","# T_1 = transforms.Compose([ transforms.ToTensor(),\n","#                 transforms.Normalize((0.5), (0.5)),\n","#                  ])\n","# T_2 = transforms.Compose([ transforms.ToTensor(),                         \n","#                 transforms.Normalize((0.5), (0.5))])\n","\n","# lr_img = T_1(lr_img).cuda().unsqueeze(0)\n","# hr_img = T_2(hr_img).cuda().unsqueeze(0)"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1643300367074,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"C88ZXlA902eW"},"outputs":[],"source":["def eval(model):\n","  lr = \"./dataset/test/6x6_256/\"\n","  hr = \"./dataset/test/3x3_256/\"\n","  num, psnr, ssim, mse, nmi= 0, 0, 0, 0, 0\n","  T_1 = transforms.Compose([ transforms.ToTensor(),\n","                transforms.Normalize((0.5), (0.5)),\n","                 ])\n","  T_2 = transforms.Compose([ transforms.ToTensor(),                         \n","                  transforms.Normalize((0.5), (0.5))])\n","  for i in tqdm(range(297)):\n","    lr_path = os.path.join(lr, str(i)+\"_3.png\")\n","    hr_path = os.path.join(hr, str(i)+\"_6.png\")\n","    if os.path.isfile(lr_path) and os.path.isfile(hr_path):\n","      lr_img = Image.open(lr_path).convert('L')\n","      hr_img = Image.open(hr_path).convert('L')\n","      \n","      lr_img = T_1(lr_img).cuda().unsqueeze(0)\n","      hr_img = T_2(hr_img).cuda().unsqueeze(0)\n","      \n","      sr_img = model(lr_img)\n","\n","      yimg = sr_img.cpu().detach().numpy().squeeze(0).squeeze(0)\n","      gtimg = hr_img.cpu().detach().numpy().squeeze(0).squeeze(0)\n","      psnr += (skimage.metrics.peak_signal_noise_ratio(yimg, gtimg))\n","      ssim += (skimage.metrics.structural_similarity(yimg, gtimg))\n","      mse += (skimage.metrics.mean_squared_error(yimg, gtimg))\n","      nmi += (skimage.metrics.normalized_mutual_information(yimg, gtimg))\n","      num += 1\n","  print(\" PSNR: %.4f SSIM: %.4f MSE: %.4f NMI: %.4f\"%(psnr/num, ssim/num, mse/num, nmi/num))\n"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1643300367074,"user":{"displayName":"Kevyn ZHANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08822570782718335276"},"user_tz":-480},"id":"zfdAIzAiVPxD"},"outputs":[],"source":["# %tensorboard --logdir=run"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJFSzgJwP-4q","outputId":"bbbc9164-ce96-48da-8abf-e39180fe2409"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch (1/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [06:04\u003c00:00,  1.23s/it]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 14.1390 SSIM: 0.1693 MSE: 0.1550 NMI: 1.0295\n","Epoch (2/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 15.4767 SSIM: 0.3265 MSE: 0.1140 NMI: 1.0425\n","Epoch (3/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 15.5727 SSIM: 0.3631 MSE: 0.1113 NMI: 1.0437\n","Epoch (4/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:06\u003c00:00,  4.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.4557 SSIM: 0.4052 MSE: 0.0911 NMI: 1.0502\n","Epoch (5/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.2642 SSIM: 0.4026 MSE: 0.0951 NMI: 1.0458\n","Epoch (6/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.4071 SSIM: 0.4097 MSE: 0.0922 NMI: 1.0466\n","Epoch (7/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.3840 SSIM: 0.4026 MSE: 0.0925 NMI: 1.0461\n","Epoch (8/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9969 SSIM: 0.4384 MSE: 0.0806 NMI: 1.0524\n","Epoch (9/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.1737 SSIM: 0.3887 MSE: 0.0971 NMI: 1.0429\n","Epoch (10/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.6084 SSIM: 0.4103 MSE: 0.0881 NMI: 1.0466\n","Epoch (11/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:03\u003c00:00,  4.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.7061 SSIM: 0.4208 MSE: 0.0862 NMI: 1.0489\n","Epoch (12/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.6917 SSIM: 0.4125 MSE: 0.0864 NMI: 1.0464\n","Epoch (13/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9457 SSIM: 0.4331 MSE: 0.0819 NMI: 1.0524\n","Epoch (14/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.8022 SSIM: 0.4350 MSE: 0.0844 NMI: 1.0491\n","Epoch (15/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:03\u003c00:00,  4.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1425 SSIM: 0.4402 MSE: 0.0781 NMI: 1.0520\n","Epoch (16/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1372 SSIM: 0.4400 MSE: 0.0782 NMI: 1.0519\n","Epoch (17/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.0931 SSIM: 0.4294 MSE: 0.0792 NMI: 1.0511\n","Epoch (18/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.2442 SSIM: 0.4449 MSE: 0.0765 NMI: 1.0526\n","Epoch (19/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.8001 SSIM: 0.4201 MSE: 0.0847 NMI: 1.0464\n","Epoch (20/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9420 SSIM: 0.4416 MSE: 0.0821 NMI: 1.0498\n","Epoch (21/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1111 SSIM: 0.4401 MSE: 0.0789 NMI: 1.0532\n","Epoch (22/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:03\u003c00:00,  4.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.6776 SSIM: 0.4084 MSE: 0.0871 NMI: 1.0476\n","Epoch (23/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1003 SSIM: 0.4413 MSE: 0.0791 NMI: 1.0522\n","Epoch (24/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.2027 SSIM: 0.4382 MSE: 0.0773 NMI: 1.0536\n","Epoch (25/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.2854 SSIM: 0.4513 MSE: 0.0758 NMI: 1.0546\n","Epoch (26/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1087 SSIM: 0.4441 MSE: 0.0791 NMI: 1.0534\n","Epoch (27/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.3266 SSIM: 0.4556 MSE: 0.0752 NMI: 1.0560\n","Epoch (28/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:06\u003c00:00,  4.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.4690 SSIM: 0.4627 MSE: 0.0727 NMI: 1.0571\n","Epoch (29/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:06\u003c00:00,  4.47it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1621 SSIM: 0.4526 MSE: 0.0779 NMI: 1.0527\n","Epoch (30/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.8946 SSIM: 0.4349 MSE: 0.0831 NMI: 1.0509\n","Epoch (31/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:06\u003c00:00,  4.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.2268 SSIM: 0.4490 MSE: 0.0770 NMI: 1.0548\n","Epoch (32/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:06\u003c00:00,  4.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9158 SSIM: 0.4330 MSE: 0.0827 NMI: 1.0501\n","Epoch (33/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.5759 SSIM: 0.4229 MSE: 0.0890 NMI: 1.0465\n","Epoch (34/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.8530 SSIM: 0.4303 MSE: 0.0838 NMI: 1.0514\n","Epoch (35/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1132 SSIM: 0.4417 MSE: 0.0790 NMI: 1.0533\n","Epoch (36/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:06\u003c00:00,  4.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9553 SSIM: 0.4452 MSE: 0.0818 NMI: 1.0509\n","Epoch (37/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.3232 SSIM: 0.4483 MSE: 0.0751 NMI: 1.0564\n","Epoch (38/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.0813 SSIM: 0.4435 MSE: 0.0795 NMI: 1.0526\n","Epoch (39/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1916 SSIM: 0.4507 MSE: 0.0776 NMI: 1.0539\n","Epoch (40/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1150 SSIM: 0.4440 MSE: 0.0790 NMI: 1.0520\n","Epoch (41/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.2405 SSIM: 0.4478 MSE: 0.0767 NMI: 1.0568\n","Epoch (42/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.0638 SSIM: 0.4395 MSE: 0.0798 NMI: 1.0518\n","Epoch (43/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1004 SSIM: 0.4439 MSE: 0.0791 NMI: 1.0519\n","Epoch (44/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.8802 SSIM: 0.4355 MSE: 0.0833 NMI: 1.0497\n","Epoch (45/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9579 SSIM: 0.4401 MSE: 0.0818 NMI: 1.0510\n","Epoch (46/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.0097 SSIM: 0.4438 MSE: 0.0810 NMI: 1.0527\n","Epoch (47/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9914 SSIM: 0.4426 MSE: 0.0812 NMI: 1.0514\n","Epoch (48/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1770 SSIM: 0.4557 MSE: 0.0779 NMI: 1.0539\n","Epoch (49/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9108 SSIM: 0.4303 MSE: 0.0826 NMI: 1.0508\n","Epoch (50/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9329 SSIM: 0.4438 MSE: 0.0825 NMI: 1.0507\n","Epoch (51/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.6109 SSIM: 0.4292 MSE: 0.0886 NMI: 1.0478\n","Epoch (52/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.52it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.5942 SSIM: 0.4279 MSE: 0.0888 NMI: 1.0466\n","Epoch (53/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.2086 SSIM: 0.4456 MSE: 0.0773 NMI: 1.0539\n","Epoch (54/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.8667 SSIM: 0.4382 MSE: 0.0836 NMI: 1.0507\n","Epoch (55/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:06\u003c00:00,  4.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.6472 SSIM: 0.4251 MSE: 0.0877 NMI: 1.0466\n","Epoch (56/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9839 SSIM: 0.4467 MSE: 0.0814 NMI: 1.0521\n","Epoch (57/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.7248 SSIM: 0.4321 MSE: 0.0864 NMI: 1.0484\n","Epoch (58/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.9150 SSIM: 0.4349 MSE: 0.0826 NMI: 1.0512\n","Epoch (59/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.7875 SSIM: 0.4327 MSE: 0.0852 NMI: 1.0496\n","Epoch (60/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:04\u003c00:00,  4.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 16.7735 SSIM: 0.4278 MSE: 0.0853 NMI: 1.0491\n","Epoch (61/100) Finished\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 297/297 [01:05\u003c00:00,  4.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":[" PSNR: 17.1031 SSIM: 0.4429 MSE: 0.0793 NMI: 1.0536\n"]}],"source":["###### Training ######\n","globaliter = 0\n","for epoch in range(epoch, n_epochs):\n","    real_out, fake_out = None, None\n","    for i, batch in enumerate(dataloader):\n","        globaliter += 1\n","        real_A = Variable(input_A.copy_(batch['A']))\n","        real_B = Variable(input_B.copy_(batch['B']))\n","\n","        ######### (1) forward #########\n","        fake_B = netG_A2B(real_A)\n","        recovered_A = netG_B2A(fake_B)\n","        fake_A = netG_B2A(real_B)\n","        recovered_B = netG_A2B(fake_A)\n","\n","\n","        ###### (2) G_A and G_B ######\n","        set_requires_grad([netD_A, netD_B], False)\n","        optimizer_G.zero_grad()\n","\n","        pred_fake = netD_B(fake_B)\n","        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n","\n","        pred_fake = netD_A(fake_A)\n","        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n","\n","        idt_A = netG_A2B(real_B)\n","        loss_idt_B = criterion_identity(idt_A, real_B) * 0.5\n","\n","        idt_B = netG_B2A(real_A)\n","        loss_idt_A = criterion_identity(idt_B, real_A) * 0.5\n","        \n","\n","        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n","        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n","\n","        loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB + loss_idt_B + loss_idt_A\n","\n","        loss_G.backward()        \n","        optimizer_G.step()\n","\n","        ###### (3) D_A and D_B ######\n","        set_requires_grad([netD_A, netD_B], True)\n","        optimizer_D.zero_grad()\n","\n","        # Real loss\n","        pred_real = netD_A(real_A)\n","        loss_D_real = criterion_GAN(pred_real, target_real)\n","        # Fake loss\n","        fake_A = fake_A_buffer.push_and_pop(fake_A)\n","        pred_fake = netD_A(fake_A.detach())\n","        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n","        # Total loss\n","        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n","        loss_D_A.backward()\n","\n","\n","        # Real loss\n","        pred_real = netD_B(real_B)\n","        loss_D_real = criterion_GAN(pred_real, target_real)      \n","        # Fake loss\n","        fake_B = fake_B_buffer.push_and_pop(fake_B)\n","        pred_fake = netD_B(fake_B.detach())\n","        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n","        # Total loss\n","        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n","        loss_D_B.backward()\n","\n","        optimizer_D.step()\n","\n","        writer.add_scalar('GAN A2B loss', loss_GAN_A2B, globaliter)\n","        writer.add_scalar('GAN B2A loss', loss_GAN_B2A, globaliter)\n","        writer.add_scalar('Cycle ABA loss', loss_cycle_ABA, globaliter)\n","        writer.add_scalar('Cycle BAB loss', loss_cycle_BAB, globaliter)\n","        writer.add_scalar('Identity A loss', loss_idt_A, globaliter)\n","        writer.add_scalar('Identity B loss', loss_idt_B, globaliter)\n","        writer.add_scalar('Dis A loss', loss_D_A, globaliter)\n","        writer.add_scalar('Dis B loss', loss_D_B, globaliter)\n","        \n","        ####################################\n","        ####################################\n","\n","        if i == 1:\n","          x = real_A.detach()\n","          real_out = x\n","          fake_out = netG_A2B(x)\n","      \n","    save_sample(epoch, real_out, \"_input\")\n","    save_sample(epoch, fake_out, \"_output\")\n","\n","    # Update learning rates\n","    lr_scheduler_G.step()\n","    lr_scheduler_D.step()\n","\n","\n","\n","    # Save models checkpoints\n","    # # torch.save(LR_encoding.state_dict(), 'output/LR_encoding.pth')\n","    # if epoch%5==4:\n","    #   torch.save(netG_A2B.state_dict(), './baseline_output/netG_A2B_epoch'+str(epoch+1)+'.pth')\n","    print(\"Epoch (%d/%d) Finished\" % (epoch+1, n_epochs))\n","\n","    # sr_img = netG_A2B(lr_img)\n","    # LPIPS = loss_fn_alex(hr_img.cpu(), sr_img.cpu())\n","\n","    # yimg = sr_img.cpu().detach().numpy().squeeze(0).squeeze(0)\n","    # hr_img_cpu = hr_img.cpu().detach().numpy().squeeze(0).squeeze(0)\n","    # psnr = skimage.metrics.peak_signal_noise_ratio(yimg, hr_img_cpu)\n","    # ssim = skimage.metrics.structural_similarity(yimg, hr_img_cpu)\n","\n","    # print((\"PSNR: %.4f SSIM: %.4f LPIPS:\"%(psnr, ssim)), LPIPS.data)\n","\n","    # if (epoch+1)%2 == 0:\n","    eval(netG_A2B)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MY-xrBjGWrvY"},"outputs":[],"source":["def result_save_sample(epoch, tensor=None, suffix=\"_real\", img=None, img_mode=False):\n","    if tensor != None:\n","      output = tensor.cpu().detach().numpy().squeeze(0).squeeze(0)\n","      plt.imsave('./results/image_baseline_'+str(epoch)+suffix+'.jpeg', output, cmap=\"gray\")\n","    if img_mode:\n","      plt.imsave('./results/image_baseline_'+str(epoch)+suffix+'.jpeg', img, cmap=\"gray\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxE5wdcc7Z3s"},"outputs":[],"source":["netG_A2B = torch.load('./baseline_output/netG_A2B_epoch100.pth')\n","type(netG_A2B)\n","model = UnetGenerator(output_nc, input_nc).cuda()\n","model.load_state_dict(netG_A2B, strict=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TDByscuTVLDY"},"outputs":[],"source":["img = dataset[0]['A']\n","x = img.unsqueeze(0).cuda()\n","plt.imshow(img.squeeze(0), \"gray\")\n","result_save_sample(1, tensor=x, suffix=\"_input\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q18OiZQRVvBQ"},"outputs":[],"source":["y = model(x)\n","yimg = y.cpu().detach().numpy().squeeze(0).squeeze(0)\n","plt.imshow(yimg, \"gray\")\n","result_save_sample(1, tensor=y, suffix=\"_output\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8sx_rdN_76NQ"},"outputs":[],"source":["import cv2\n","upsample = cv2.resize(img.squeeze(0).cpu().numpy(), dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n","upsample.shape\n","result_save_sample(1, img_mode=True, img=upsample, suffix=\"_interpolation\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1kIx7Yy45zMm"},"outputs":[],"source":["import numpy as np\n","import cv2\n","from matplotlib import pyplot as plt\n","netG_A2B = torch.load('./baseline_output/netG_A2B_epoch100.pth')\n","type(netG_A2B)\n","model = UnetGenerator(output_nc, input_nc).cuda()\n","model.load_state_dict(netG_A2B, strict=False)\n","y = model(x)\n","\n","# img = x.cpu().detach().numpy().squeeze(0).squeeze(0)\n","img = y.cpu().detach().numpy().squeeze(0).squeeze(0)\n","f = np.fft.fft2(img, axes=(-2, -1))\n","fshift = np.fft.fftshift(f)\n","res = np.log(np.abs(fshift))\n","pha = np.angle(fshift)\n","plt.figure(figsize=(11, 11))\n","plt.subplot(121), plt.imshow(img, 'gray')#, plt.title('Original Image')\n","plt.axis('off')\n","plt.subplot(122), plt.imshow(res, 'gray')#, plt.title('Fourier Amplitude')\n","plt.axis('off')\n","# plt.subplot(333), plt.imshow(pha, 'gray')#, plt.title('Fourier Phase')\n","# plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-pqtNTNiriZA"},"outputs":[],"source":["img = dataset[0]['A']\n","x = img.unsqueeze(0).cuda()\n","plt.imshow(img.squeeze(0), \"gray\")\n","plt.axis('off')\n","y = model(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSMpsnMRs0Od"},"outputs":[],"source":["yimg = y.cpu().detach().numpy().squeeze(0).squeeze(0)\n","plt.imshow(yimg, \"gray\")\n","plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SapXEU8t80Z"},"outputs":[],"source":["class Test_ImageDataset(Dataset):\n","    def __init__(self, root, transforms_test=None, unaligned=False, mode='test'):\n","        self.transformA = transforms.Compose(transforms_test)\n","        self.transformB = transforms.Compose(transforms_test)\n","\n","        self.unaligned = unaligned\n","\n","        self.files_A = sorted(glob.glob(os.path.join(root, '6x6_256/') + '/*.*'))\n","        self.files_B = sorted(glob.glob(os.path.join(root, '3x3_256/') + '/*.*'))\n","\n","    def __getitem__(self, index):\n","        img_A = Image.open(self.files_A[index % len(self.files_A)]).convert('L')\n","        print(self.files_A[index % len(self.files_A)])\n","        item_A = self.transformA(img_A)\n","\n","        item_B = self.transformB(Image.open(\"./test/3x3_256/102_6.png\").convert('L'))\n","\n","        return {'A': item_A, 'B': item_B}\n","\n","    def __len__(self):\n","        return max(len(self.files_A), len(self.files_B))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0z0kn-ttTIp"},"outputs":[],"source":["test_path = \"./test/\"\n","transforms_test = [ \n","                transforms.ToTensor(),\n","                # transforms.Normalize((0.246), (0.170)),\n","                transforms.Normalize((0.5), (0.5)) ]\n","test_dataset = Test_ImageDataset(test_path, transforms_test=transforms_test, unaligned=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2d-44PjtpXF"},"outputs":[],"source":["import cv2\n","img = test_dataset[2]['A']\n","gt = test_dataset[2]['B']\n","print(img.shape)\n","# img = cv2.resize(img.squeeze(0).cpu().numpy(), dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n","x = torch.tensor(img).unsqueeze(0).cuda()\n","# plt.imshow(img.squeeze(0), \"gray\")\n","y = model(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfLnAKqHCA1Q"},"outputs":[],"source":["plt.imshow(img.squeeze(0), \"gray\")\n","plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rYtgrHoaCvyT"},"outputs":[],"source":["plt.imshow(gt.squeeze(0), \"gray\")\n","plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOKsvPrivP5s"},"outputs":[],"source":["yimg = y.cpu().detach().numpy().squeeze(0).squeeze(0)\n","plt.imshow(yimg, \"gray\")\n","plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsLSjkgKCKwJ"},"outputs":[],"source":["f = np.fft.fft2(yimg, axes=(-2, -1))\n","fshift = np.fft.fftshift(f)\n","res = np.log(np.abs(fshift))\n","pha = np.angle(fshift)\n","plt.figure(figsize=(11, 11))\n","plt.subplot(331), plt.imshow(yimg, 'gray'), plt.title('Original Image')\n","plt.axis('off')\n","plt.subplot(332), plt.imshow(res, 'gray'), plt.title('Fourier Amplitude')\n","plt.axis('off')\n","plt.subplot(333), plt.imshow(pha, 'gray'), plt.title('Fourier Phase')\n","plt.axis('off')"]},{"cell_type":"markdown","metadata":{"id":"oAR5512tDS_4"},"source":["Pick a pair of test data to evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ASluKPxzGWDv"},"outputs":[],"source":["netG_A2B = torch.load('./baseline_output/netG_A2B_epoch40.pth')\n","type(netG_A2B)\n","model = UnetGeneratorA2B(output_nc, input_nc).cuda()\n","model.load_state_dict(netG_A2B, strict=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"kNaXAuyNDSjZ"},"outputs":[],"source":["lr_img = Image.open(\"./test/6x6_256/270_3.png\").convert('L')\n","hr_img = Image.open(\"./test/3x3_256/270_6.png\").convert('L')\n","# lr_img = Image.open(\"./dataset/Colab_centered_OCTA/trainA/STDR403_20181029_101618_Angio (1)_R_001.png\").convert('L')\n","# hr_img = Image.open(\"./dataset/Colab_centered_OCTA/trainB/STDR403_20181029_101802_Angio (1)_R_001.png\").convert('L')\n","T_1 = transforms.Compose([ transforms.ToTensor(),\n","                transforms.Normalize((0.5), (0.5)),\n","                transforms.Resize([128, 128]) ])\n","T_2 = transforms.Compose([ transforms.ToTensor(),\n","                transforms.Normalize((0.5), (0.5))])\n","# lr_img = cv2.resize(np.array(lr_img), dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n","# lr_img = torch.tensor(lr_img).unsqueeze(0).unsqueeze(0).cuda()\n","lr_img = T_1(lr_img).cuda().unsqueeze(0)\n","hr_img = T_2(hr_img).cuda().unsqueeze(0)\n","# lr_img.size()\n","sr_img = model(lr_img)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"J7h1kFh5EJVv"},"outputs":[],"source":["ximg = lr_img.cpu().detach().numpy().squeeze(0).squeeze(0)\n","print(ximg.shape)\n","plt.imshow(ximg, \"gray\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ehtYEwRXEG7P"},"outputs":[],"source":["yimg = sr_img.cpu().detach().numpy().squeeze(0).squeeze(0)\n","plt.imshow(yimg, \"gray\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9NMCtYavERnP"},"outputs":[],"source":["gtimg = hr_img.cpu().detach().numpy().squeeze(0).squeeze(0)\n","plt.imshow(gtimg, \"gray\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ks2aLGjDvgwL"},"outputs":[],"source":["import skimage.metrics\n","print(skimage.metrics.peak_signal_noise_ratio(yimg, gtimg))\n","print(skimage.metrics.structural_similarity(yimg, gtimg))"]},{"cell_type":"markdown","metadata":{"id":"03jaeTVrzWae"},"source":["# Result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qSrWyz5t-d2A"},"outputs":[],"source":["import skimage.metrics\n","print(skimage.metrics.peak_signal_noise_ratio(yimg, gtimg))\n","print(skimage.metrics.structural_similarity(yimg, gtimg))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rKMXdTjrxsBP"},"outputs":[],"source":["lr_img = Image.open(\"./test/6x6_256/270_3.png\").convert('L')\n","hr_img = Image.open(\"./test/3x3_256/270_6.png\").convert('L')\n","lr_img = T_1(lr_img)\n","hr_img = T_2(hr_img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKQZG5b9ywEQ"},"outputs":[],"source":["input = lr_img.cuda().unsqueeze(0)\n","output = model(input)\n","# output = output.cpu().detach().numpy().squeeze(0).squeeze(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DlJnah58Cc1S"},"outputs":[],"source":["d = loss_fn_alex(hr_img.cpu(), output.cpu())\n","print(d)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5YPToahC4hc"},"outputs":[],"source":["x = F.interpolate(input, scale_factor=2, mode='nearest')\n","d = loss_fn_alex(hr_img.cpu(), x.cpu())\n","print(d)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"OCTA_Cyclegan_baseline_UNet_emp.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}